from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_openai import AzureChatOpenAI
from langchain_core.runnables import RunnableLambda
import os
from dotenv import load_dotenv

load_dotenv()

llm = AzureChatOpenAI(
    azure_deployment=os.getenv("AOAI_DEPLOY_GPT4O_MINI"),
    openai_api_version="2024-02-01",
    api_key=os.getenv("AOAI_API_KEY"),
    azure_endpoint=os.getenv("AOAI_ENDPOINT"),
    temperature=0.3,
)

prompt = ChatPromptTemplate.from_messages(
    [
        (
            "system",
            "You are a document assistant that answers questions based on the given technical paper.",
        ),
        (
            "user",
            "ë¬¸ì„œ: ì´ ë…¼ë¬¸ì€ ê°•í™”í•™ìŠµ ê¸°ë°˜ìœ¼ë¡œ ë“œë¡ ì˜ ë¹„í–‰ ì œì–´ë¥¼ ìë™í™”í•˜ì˜€ìŠµë‹ˆë‹¤.\nì§ˆë¬¸: ì´ ë…¼ë¬¸ì˜ í•µì‹¬ ê¸°ìˆ ì€ ë¬´ì—‡ì¸ê°€ìš”?",
        ),
        (
            "assistant",
            "ì´ ë…¼ë¬¸ì˜ í•µì‹¬ ê¸°ìˆ ì€ ê°•í™”í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ì„ ë¹„í–‰ ì œì–´ ì‹œìŠ¤í…œì— ì ìš©í•œ ì ì…ë‹ˆë‹¤.",
        ),
        (
            "user",
            "ë¬¸ì„œ: ì´ ë…¼ë¬¸ì€ ììœ¨ì£¼í–‰ ì°¨ëŸ‰ì˜ ì„¼ì„œ ìœµí•© ì‹œìŠ¤í…œì— ëŒ€í•´ ë‹¤ë£¹ë‹ˆë‹¤.\nì§ˆë¬¸: ì´ ë…¼ë¬¸ì˜ í•µì‹¬ ê¸°ìˆ ì€ ë¬´ì—‡ì¸ê°€ìš”?",
        ),
        (
            "assistant",
            "ì´ ë…¼ë¬¸ì€ ë‹¤ì–‘í•œ ì„¼ì„œ ë°ì´í„°ë¥¼ í†µí•©í•˜ì—¬ ììœ¨ì£¼í–‰ ì •í™•ë„ë¥¼ ë†’ì´ëŠ” ì„¼ì„œ ìœµí•© ê¸°ìˆ ì´ í•µì‹¬ì…ë‹ˆë‹¤.",
        ),
        ("user", "{user_input}"),
    ]
)
chain = prompt | llm | StrOutputParser()

summarizer_agent = RunnableLambda(
    lambda state: {
        "summary": chain.invoke(
            {
                "user_input": f"ë‹¤ìŒì€ ë…¼ë¬¸ ë‚´ìš©ì…ë‹ˆë‹¤:\n{state['raw_text'][:5000]}\n\nìš”ì•½í•´ì¤˜"
            }
        )
    }
)


def qa_with_retrieval(state):
    query = state.get("user_input", "")
    retriever = state.get("retriever", None)
    if retriever is None:
        return {
            "answer": "ğŸ’¡ ë¬¸ì„œë¥¼ ì„ë² ë”©í•˜ê±°ë‚˜ ê²€ìƒ‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. retrieverê°€ ì—†ìŠµë‹ˆë‹¤."
        }

    docs = retriever.get_relevant_documents(query)
    if not docs:
        return {
            "answer": "ğŸ’¡ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë…¼ë¬¸ ë‚´ìš©ì´ í¬í•¨ëœ PDFë¥¼ ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”."
        }

    context = "\n".join([doc.page_content for doc in docs])
    user_prompt = f"ë‹¤ìŒì€ ê´€ë ¨ ë…¼ë¬¸ ë‚´ìš©ì…ë‹ˆë‹¤:\n{context}\n\nì‚¬ìš©ì ì§ˆë¬¸:\n{query}"
    return {"answer": chain.invoke({"user_input": user_prompt})}


qa_agent = RunnableLambda(qa_with_retrieval)
